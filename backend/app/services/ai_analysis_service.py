"""
AI Analysis Service - Uses LOCAL AI for root cause analysis
Generated by RTX 5090 (Qwen2.5-Coder-32B-AWQ)

This service calls the LOCAL AI (RTX 5090) to analyze data quality issues
and provide root cause analysis and recommendations.
"""
import httpx
import json
import logging
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Optional
import asyncio
import os

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# LOCAL AI endpoint (RTX 5090)
LOCAL_AI_URL = os.getenv("LOCAL_AI_URL", "http://localhost:8004/v1/chat/completions")
LOCAL_AI_MODEL = os.getenv("LOCAL_AI_MODEL", "Qwen/Qwen2.5-Coder-32B-Instruct-AWQ")


@dataclass
class AIAnalysisResult:
    """Result of AI-powered root cause analysis."""
    root_causes: List[str]
    recommendations: List[str]
    confidence_score: float
    additional_rules: List[Dict[str, str]]
    raw_response: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "root_causes": self.root_causes,
            "recommendations": self.recommendations,
            "confidence_score": self.confidence_score,
            "additional_rules": self.additional_rules
        }


def construct_analysis_prompt(
    violations: List[Dict[str, Any]],
    profile_data: Dict[str, Any],
    table_name: str
) -> str:
    """Construct a prompt for the AI to analyze data quality issues."""
    prompt = f"""You are a data quality expert. Analyze the following data quality issues and provide root cause analysis.

## Table: {table_name}

## Profile Summary:
- Row Count: {profile_data.get('row_count', 'N/A')}
- Column Count: {profile_data.get('column_count', 'N/A')}

## Violations Found:
"""
    for v in violations:
        prompt += f"- {v.get('rule_type', 'Unknown')}: {v.get('column', 'N/A')} - {v.get('violation_count', 0)} violations\n"

    prompt += """
## Please provide:
1. ROOT CAUSES (list each on a new line starting with "- ")
2. RECOMMENDATIONS (list each on a new line starting with "- ")
3. CONFIDENCE SCORE (0.0 to 1.0)
4. ADDITIONAL RULES TO CREATE (list each on a new line with format: "- RULE_TYPE: column_name - description")

Format your response exactly like this:

ROOT CAUSES:
- [cause 1]
- [cause 2]

RECOMMENDATIONS:
- [recommendation 1]
- [recommendation 2]

CONFIDENCE: 0.85

ADDITIONAL RULES:
- NULL_CHECK: column_name - description
"""
    return prompt


def parse_ai_response(response_text: str) -> AIAnalysisResult:
    """Parse the AI response into structured data."""
    root_causes = []
    recommendations = []
    confidence_score = 0.75  # default
    additional_rules = []

    current_section = None
    lines = response_text.strip().split('\n')

    for line in lines:
        line = line.strip()

        if line.upper().startswith('ROOT CAUSES'):
            current_section = 'root_causes'
        elif line.upper().startswith('RECOMMENDATIONS'):
            current_section = 'recommendations'
        elif line.upper().startswith('CONFIDENCE'):
            current_section = 'confidence'
            # Try to extract score from same line
            try:
                parts = line.split(':')
                if len(parts) > 1:
                    confidence_score = float(parts[1].strip())
            except ValueError:
                pass
        elif line.upper().startswith('ADDITIONAL RULES'):
            current_section = 'additional_rules'
        elif line.startswith('- ') or line.startswith('* '):
            content = line[2:].strip()
            if current_section == 'root_causes':
                root_causes.append(content)
            elif current_section == 'recommendations':
                recommendations.append(content)
            elif current_section == 'additional_rules':
                # Parse rule format: "RULE_TYPE: column - description"
                if ':' in content:
                    parts = content.split(':', 1)
                    rule_type = parts[0].strip()
                    rest = parts[1].strip() if len(parts) > 1 else ""
                    additional_rules.append({
                        "rule_type": rule_type,
                        "description": rest
                    })
        elif current_section == 'confidence' and line:
            try:
                confidence_score = float(line)
            except ValueError:
                pass

    return AIAnalysisResult(
        root_causes=root_causes or ["No specific root causes identified"],
        recommendations=recommendations or ["Review data ingestion process"],
        confidence_score=confidence_score,
        additional_rules=additional_rules,
        raw_response=response_text
    )


async def analyze_data_quality(
    violations: List[Dict[str, Any]],
    profile_data: Dict[str, Any],
    table_name: str,
    timeout: int = 60,
    retries: int = 3
) -> AIAnalysisResult:
    """
    Analyze data quality issues using LOCAL AI.

    Args:
        violations: List of rule violations
        profile_data: Table profile data
        table_name: Name of the table being analyzed
        timeout: Request timeout in seconds
        retries: Number of retry attempts

    Returns:
        AIAnalysisResult with root causes and recommendations
    """
    prompt = construct_analysis_prompt(violations, profile_data, table_name)

    payload = {
        "model": LOCAL_AI_MODEL,
        "messages": [
            {
                "role": "system",
                "content": "You are a data quality expert. Analyze data issues and provide actionable recommendations."
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        "temperature": 0.3,
        "max_tokens": 1500
    }

    headers = {"Content-Type": "application/json"}

    async with httpx.AsyncClient(timeout=httpx.Timeout(timeout)) as client:
        last_error = None
        for attempt in range(retries):
            try:
                logger.info(f"Calling LOCAL AI for analysis (attempt {attempt + 1}/{retries})")
                response = await client.post(LOCAL_AI_URL, headers=headers, json=payload)
                response.raise_for_status()

                data = response.json()
                content = data.get('choices', [{}])[0].get('message', {}).get('content', '')

                if content:
                    logger.info("AI analysis completed successfully")
                    return parse_ai_response(content)
                else:
                    logger.warning("Empty response from LOCAL AI")

            except httpx.RequestError as e:
                last_error = e
                logger.warning(f"Request error: {e}")
            except httpx.HTTPStatusError as e:
                last_error = e
                logger.warning(f"HTTP error: {e}")
            except Exception as e:
                last_error = e
                logger.error(f"Unexpected error: {e}")

            if attempt < retries - 1:
                await asyncio.sleep(2 ** attempt)  # Exponential backoff

        # Return fallback result if all retries failed
        logger.error(f"All retries failed. Last error: {last_error}")
        return AIAnalysisResult(
            root_causes=["Unable to complete AI analysis - service unavailable"],
            recommendations=["Check LOCAL AI service status", "Review violations manually"],
            confidence_score=0.0,
            additional_rules=[],
            raw_response=str(last_error)
        )
