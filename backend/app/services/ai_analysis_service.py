"""
AI Analysis Service
Generated by: RTX 5090 (architecture), RTX 3050 (implementation), Expert AI (enhancement)
Provides AI-powered data quality analysis and anomaly detection
"""
import logging
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from datetime import datetime

logger = logging.getLogger(__name__)


@dataclass
class Insight:
    """Data quality insight."""
    insight_id: str
    category: str
    description: str
    recommendation: str
    severity: str  # low, medium, high
    affected_columns: List[str]


@dataclass
class Anomaly:
    """Detected anomaly in data."""
    anomaly_id: str
    anomaly_type: str
    table_name: str
    column_name: Optional[str]
    details: str
    detected_at: datetime
    severity: str


class AIAnalysisService:
    """
    AI-powered data quality analysis service.
    
    Generated by RTX 3050, enhanced by Expert AI.
    Uses statistical analysis to detect anomalies and generate insights.
    """

    def __init__(self, pool=None):
        """Initialize with database pool."""
        self._pool = pool

    async def analyze_profile(self, profile_data: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze profiling results and generate insights."""
        insights = []
        table_name = profile_data.get("table_name", "unknown")
        columns = profile_data.get("columns", [])
        row_count = profile_data.get("row_count", 0)

        for col in columns:
            col_name = col.get("column_name", "")
            null_pct = col.get("null_percentage", 0) or 0
            distinct_pct = col.get("distinct_percentage", 0) or 0

            if null_pct > 50:
                insights.append(Insight(
                    insight_id=f"null_{table_name}_{col_name}",
                    category="data_quality",
                    description=f"Column {col_name} has {null_pct:.1f}% null values",
                    recommendation="Consider adding NOT NULL constraint",
                    severity="high" if null_pct > 80 else "medium",
                    affected_columns=[col_name]
                ))

            if 0 < distinct_pct < 5 and row_count > 100:
                insights.append(Insight(
                    insight_id=f"enum_{table_name}_{col_name}",
                    category="optimization",
                    description=f"Column {col_name} has low cardinality ({distinct_pct:.1f}%)",
                    recommendation="Consider using ENUM type or lookup table",
                    severity="low",
                    affected_columns=[col_name]
                ))

        return {
            "table_name": table_name,
            "analysis_timestamp": datetime.utcnow().isoformat(),
            "insights": [asdict(i) for i in insights],
            "insight_count": len(insights)
        }

    async def detect_anomalies(self, table_stats: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Detect anomalies in table statistics."""
        anomalies = []
        now = datetime.utcnow()

        for table_name, stats in table_stats.items():
            row_count = stats.get("row_count", 0)
            if row_count > 10_000_000:
                anomalies.append(Anomaly(
                    anomaly_id=f"large_table_{table_name}",
                    anomaly_type="performance",
                    table_name=table_name,
                    column_name=None,
                    details=f"Table has {row_count:,} rows",
                    detected_at=now,
                    severity="medium"
                ))
            if row_count == 0:
                anomalies.append(Anomaly(
                    anomaly_id=f"empty_table_{table_name}",
                    anomaly_type="data_completeness",
                    table_name=table_name,
                    column_name=None,
                    details="Table has no data",
                    detected_at=now,
                    severity="medium"
                ))

        return [asdict(a) for a in anomalies]


_ai_analysis_service: Optional[AIAnalysisService] = None

async def get_ai_analysis_service(pool=None) -> AIAnalysisService:
    global _ai_analysis_service
    if _ai_analysis_service is None:
        _ai_analysis_service = AIAnalysisService(pool)
    return _ai_analysis_service


# Backward compatibility wrapper for api_routes.py
async def analyze_data_quality(profile_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Backward-compatible wrapper for AI analysis.

    Args:
        profile_data: Profiling results to analyze

    Returns:
        Analysis results with insights
    """
    service = await get_ai_analysis_service()
    return await service.analyze_profile(profile_data)
