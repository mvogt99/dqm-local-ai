"""
Real Data Profiling Service - Connects to PostgreSQL
Generated by RTX 5090 (Qwen2.5-Coder-32B-AWQ)
Enhanced with centralized configuration (RTX 3050)
Enhanced by Expert AI (Claude Opus 4.5) - Added profile storage and retrieval

V74: Added get_stored_results for DQ rule suggestions
"""
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
from datetime import datetime
import asyncpg
import json
import logging

from app.config import settings

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Use centralized configuration
DATABASE_URL = settings.DATABASE_URL
TABLE_WHITELIST = settings.TABLE_WHITELIST


@dataclass
class ColumnProfile:
    """Profile of a single column."""
    column_name: str
    data_type: str
    is_nullable: bool
    null_count: int
    null_percent: float
    unique_count: int
    min_value: Optional[Any]
    max_value: Optional[Any]
    sample_values: List[Any]


@dataclass
class TableProfile:
    """Complete profile of a table."""
    table_name: str
    row_count: int
    column_count: int
    columns: List[ColumnProfile]

    def to_dict(self) -> Dict[str, Any]:
        return {
            "table_name": self.table_name,
            "row_count": self.row_count,
            "column_count": self.column_count,
            "columns": [asdict(col) for col in self.columns]
        }


class DataProfilingService:
    """Service for profiling database tables with REAL queries."""

    def __init__(self, database_url: str = None):
        self.database_url = database_url or DATABASE_URL
        self.pool: Optional[asyncpg.Pool] = None

    async def connect(self) -> None:
        """Create connection pool."""
        self.pool = await asyncpg.create_pool(self.database_url, min_size=2, max_size=10)
        logger.info("Database connection pool created")

    async def disconnect(self) -> None:
        """Close connection pool."""
        if self.pool:
            await self.pool.close()
            logger.info("Database connection pool closed")

    async def get_tables(self) -> List[str]:
        """Get list of available tables (filtered by whitelist)."""
        query = """
        SELECT table_name
        FROM information_schema.tables
        WHERE table_schema = 'public' AND table_type = 'BASE TABLE'
        """
        async with self.pool.acquire() as conn:
            rows = await conn.fetch(query)
            tables = [row['table_name'] for row in rows]
            return [t for t in tables if t in TABLE_WHITELIST]

    async def profile_table(self, table_name: str) -> TableProfile:
        """Profile a table with REAL database queries."""
        if table_name not in TABLE_WHITELIST:
            raise ValueError(f"Table '{table_name}' is not in the whitelist")

        async with self.pool.acquire() as conn:
            # Get row count
            row_count = await self._get_row_count(conn, table_name)

            # Get column info
            columns_info = await self._get_columns_info(conn, table_name)

            # Profile each column
            column_profiles = []
            for col_info in columns_info:
                profile = await self._profile_column(
                    conn, table_name, col_info, row_count
                )
                column_profiles.append(profile)

            return TableProfile(
                table_name=table_name,
                row_count=row_count,
                column_count=len(column_profiles),
                columns=column_profiles
            )

    async def _get_row_count(self, conn: asyncpg.Connection, table_name: str) -> int:
        """Get row count for a table.

        SECURITY NOTE: table_name is validated against TABLE_WHITELIST before this
        method is called (see profile_table). PostgreSQL identifier quoting prevents
        SQL injection. asyncpg doesn't support parameterized identifiers ($1 for tables).
        """
        # SECURITY: Safe because table_name is pre-validated against TABLE_WHITELIST
        row = await conn.fetchrow(f'SELECT COUNT(*) as cnt FROM "{table_name}"')
        return row['cnt'] if row else 0

    async def _get_columns_info(self, conn: asyncpg.Connection, table_name: str) -> List[Dict]:
        """Get column information from information_schema."""
        query = """
        SELECT column_name, data_type, is_nullable
        FROM information_schema.columns
        WHERE table_name = $1 AND table_schema = 'public'
        ORDER BY ordinal_position
        """
        rows = await conn.fetch(query, table_name)
        return [dict(row) for row in rows]

    async def _profile_column(
        self,
        conn: asyncpg.Connection,
        table_name: str,
        col_info: Dict,
        row_count: int
    ) -> ColumnProfile:
        """Profile a single column.

        SECURITY NOTE: table_name and column_name are validated:
        - table_name: Validated against TABLE_WHITELIST in profile_table()
        - column_name: Comes from information_schema query (trusted source)
        PostgreSQL identifier quoting ("{identifier}") prevents SQL injection.
        """
        column_name = col_info['column_name']
        data_type = col_info['data_type']
        is_nullable = col_info['is_nullable'] == 'YES'

        # Null count
        null_row = await conn.fetchrow(
            f'SELECT COUNT(*) as cnt FROM "{table_name}" WHERE "{column_name}" IS NULL'
        )
        null_count = null_row['cnt'] if null_row else 0
        null_percent = (null_count / row_count * 100) if row_count > 0 else 0

        # Unique count
        unique_row = await conn.fetchrow(
            f'SELECT COUNT(DISTINCT "{column_name}") as cnt FROM "{table_name}"'
        )
        unique_count = unique_row['cnt'] if unique_row else 0

        # Min/Max for numeric types
        min_value = None
        max_value = None
        if data_type in ('integer', 'smallint', 'bigint', 'decimal', 'numeric',
                         'real', 'double precision', 'money'):
            try:
                minmax_row = await conn.fetchrow(
                    f'SELECT MIN("{column_name}") as min_val, MAX("{column_name}") as max_val FROM "{table_name}"'
                )
                if minmax_row:
                    min_value = minmax_row['min_val']
                    max_value = minmax_row['max_val']
            except Exception as e:
                logger.warning(f"Could not get min/max for {column_name}: {e}")

        # Sample values
        sample_rows = await conn.fetch(
            f'SELECT "{column_name}" FROM "{table_name}" WHERE "{column_name}" IS NOT NULL LIMIT 5'
        )
        sample_values = [row[column_name] for row in sample_rows]

        return ColumnProfile(
            column_name=column_name,
            data_type=data_type,
            is_nullable=is_nullable,
            null_count=null_count,
            null_percent=round(null_percent, 2),
            unique_count=unique_count,
            min_value=min_value,
            max_value=max_value,
            sample_values=sample_values
        )

    async def _ensure_profiling_tables(self, conn: asyncpg.Connection) -> None:
        """Ensure profiling results table exists."""
        await conn.execute('''
            CREATE TABLE IF NOT EXISTS profiling_results (
                id SERIAL PRIMARY KEY,
                table_name VARCHAR(255) NOT NULL,
                column_name VARCHAR(255) NOT NULL,
                data_type VARCHAR(100),
                null_count INTEGER DEFAULT 0,
                null_percent REAL DEFAULT 0,
                unique_count INTEGER DEFAULT 0,
                min_value TEXT,
                max_value TEXT,
                sample_values JSONB,
                profiled_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        # Create index for faster lookups
        await conn.execute('''
            CREATE INDEX IF NOT EXISTS idx_profiling_results_table
            ON profiling_results(table_name, column_name)
        ''')

    async def store_profile(self, profile: TableProfile) -> None:
        """Store a table profile in the database for later retrieval."""
        async with self.pool.acquire() as conn:
            await self._ensure_profiling_tables(conn)

            # Delete existing results for this table
            await conn.execute(
                'DELETE FROM profiling_results WHERE table_name = $1',
                profile.table_name
            )

            # Insert new results
            for col in profile.columns:
                await conn.execute('''
                    INSERT INTO profiling_results
                    (table_name, column_name, data_type, null_count, null_percent,
                     unique_count, min_value, max_value, sample_values)
                    VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
                ''',
                    profile.table_name,
                    col.column_name,
                    col.data_type,
                    col.null_count,
                    col.null_percent,
                    col.unique_count,
                    str(col.min_value) if col.min_value is not None else None,
                    str(col.max_value) if col.max_value is not None else None,
                    json.dumps(col.sample_values, default=str)
                )

            logger.info(f"Stored profile for table {profile.table_name} ({len(profile.columns)} columns)")

    async def get_stored_results(
        self,
        table_name: Optional[str] = None,
        limit: int = 50
    ) -> List[Dict[str, Any]]:
        """
        Retrieve stored profiling results for rule suggestion.

        Args:
            table_name: Optional table filter
            limit: Maximum number of results

        Returns:
            List of profiling results suitable for rule suggestion
        """
        async with self.pool.acquire() as conn:
            await self._ensure_profiling_tables(conn)

            if table_name:
                if table_name not in TABLE_WHITELIST:
                    raise ValueError(f"Table '{table_name}' is not in the whitelist")

                results = await conn.fetch('''
                    SELECT table_name, column_name, data_type, null_count, null_percent,
                           unique_count, min_value, max_value, sample_values, profiled_at
                    FROM profiling_results
                    WHERE table_name = $1
                    ORDER BY profiled_at DESC
                    LIMIT $2
                ''', table_name, limit)
            else:
                results = await conn.fetch('''
                    SELECT table_name, column_name, data_type, null_count, null_percent,
                           unique_count, min_value, max_value, sample_values, profiled_at
                    FROM profiling_results
                    ORDER BY profiled_at DESC
                    LIMIT $1
                ''', limit)

            return [
                {
                    'table_name': r['table_name'],
                    'column_name': r['column_name'],
                    'data_type': r['data_type'],
                    'null_count': r['null_count'],
                    'null_percent': r['null_percent'],
                    'unique_count': r['unique_count'],
                    'min_value': r['min_value'],
                    'max_value': r['max_value'],
                    'sample_values': r['sample_values'] if r['sample_values'] else [],
                    'profiled_at': r['profiled_at'].isoformat() if r['profiled_at'] else None
                }
                for r in results
            ]

    async def profile_and_store(self, table_name: str) -> TableProfile:
        """Profile a table and store results for later use."""
        profile = await self.profile_table(table_name)
        await self.store_profile(profile)
        return profile

    async def profile_all_tables(self) -> List[TableProfile]:
        """Profile all whitelisted tables and store results."""
        tables = await self.get_tables()
        profiles = []
        for table in tables:
            try:
                profile = await self.profile_and_store(table)
                profiles.append(profile)
                logger.info(f"Profiled and stored: {table}")
            except Exception as e:
                logger.error(f"Failed to profile {table}: {e}")
        return profiles


# Singleton instance
_profiling_service: Optional[DataProfilingService] = None


async def get_profiling_service() -> DataProfilingService:
    """Get or create profiling service singleton."""
    global _profiling_service
    if _profiling_service is None:
        _profiling_service = DataProfilingService()
        await _profiling_service.connect()
    return _profiling_service
