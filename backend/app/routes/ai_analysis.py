"""
AI Analysis Routes - Enhanced
Generated by: RTX 3050 (skeleton), Expert AI (enhancement)

V90: Added RCA feature parity endpoints
- POST /analyze/{result_id} - Analyze specific DQ failure
- POST /batch-analyze - Batch analyze failures
- GET /analyses - Get stored analyses
"""
from fastapi import APIRouter, HTTPException, Query
from typing import Optional, Dict, Any, List
from pydantic import BaseModel

from app.services.ai_analysis_service import get_ai_analysis_service
from app.services.data_profiling_service import get_profiling_service
from app.config import settings

router = APIRouter(
    prefix="/ai-analysis",
    tags=["AI Analysis"]
)


class AnalysisRequest(BaseModel):
    table_name: Optional[str] = None
    include_anomalies: bool = True


class AnomalyRequest(BaseModel):
    tables: Optional[list] = None


class BatchAnalyzeRequest(BaseModel):
    """V90: Request model for batch analysis."""
    result_ids: List[int]


@router.post("/analyze")
async def analyze_data_quality(request: AnalysisRequest):
    """Analyze data quality using AI-powered analysis."""
    try:
        ai_service = await get_ai_analysis_service()
        profiling_service = await get_profiling_service()
        
        # Get profiling data
        if request.table_name:
            profile = await profiling_service.profile_table(request.table_name)
            # Use to_dict() for TableProfile dataclass
            profile_data = profile.to_dict() if hasattr(profile, 'to_dict') else (
                profile.dict() if hasattr(profile, 'dict') else profile
            )
        else:
            tables = await profiling_service.get_tables()
            profile_data = {"tables": tables[:5]}  # Limit for demo
        
        # Analyze
        result = await ai_service.analyze_profile(profile_data)
        
        return {
            "status": "success",
            "analysis": result
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/anomalies/detect")
async def detect_anomalies(request: AnomalyRequest):
    """Detect anomalies in data quality metrics."""
    try:
        ai_service = await get_ai_analysis_service()
        profiling_service = await get_profiling_service()
        
        # Build table stats
        tables = request.tables or await profiling_service.get_tables()
        table_stats = {}
        for table in tables[:10]:  # Limit
            try:
                count = await profiling_service.get_row_count(table)
                table_stats[table] = {"row_count": count, "total_columns": 10}
            except:
                continue
        
        anomalies = await ai_service.detect_anomalies(table_stats)
        
        return {
            "status": "success",
            "anomalies": anomalies,
            "tables_analyzed": len(table_stats)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/insights/{table_name}")
async def get_table_insights(table_name: str):
    """Get AI-generated insights for a specific table."""
    try:
        ai_service = await get_ai_analysis_service()
        profiling_service = await get_profiling_service()

        profile = await profiling_service.profile_table(table_name)
        # Use to_dict() for TableProfile dataclass
        profile_data = profile.to_dict() if hasattr(profile, 'to_dict') else (
            profile.dict() if hasattr(profile, 'dict') else {"table_name": table_name, "columns": [], "row_count": 0}
        )

        result = await ai_service.analyze_profile(profile_data)

        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# =============================================================================
# V90: RCA Feature Parity Endpoints
# =============================================================================

@router.post("/analyze/{result_id}")
async def analyze_failure(result_id: int):
    """
    V90: Analyze a specific DQ result failure.
    Feature parity with Expert AI.
    """
    try:
        ai_service = await get_ai_analysis_service()
        analysis = await ai_service.analyze_failure(result_id, settings.DATABASE_URL)

        return {
            "result_id": analysis.result_id,
            "root_cause": analysis.suggested_cause,
            "confidence_score": analysis.confidence_score,
            "evidence": analysis.supporting_evidence,
            "remediation": analysis.remediation_steps,
            "ai_model": analysis.ai_model
        }
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/batch-analyze")
async def batch_analyze(request: BatchAnalyzeRequest):
    """
    V90: Analyze multiple DQ failures in batch.
    Feature parity with Expert AI.
    """
    try:
        ai_service = await get_ai_analysis_service()
        analyses = await ai_service.batch_analyze(request.result_ids, settings.DATABASE_URL)

        return {
            "analyzed": len(analyses),
            "results": [
                {
                    "result_id": a.result_id,
                    "root_cause": a.suggested_cause,
                    "confidence_score": a.confidence_score
                }
                for a in analyses
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/analyses")
async def get_analyses(
    limit: int = Query(50, ge=1, le=100, description="Maximum analyses to return")
):
    """
    V90: Get stored analyses.
    Feature parity with Expert AI.
    """
    try:
        ai_service = await get_ai_analysis_service()
        analyses = await ai_service.get_analyses(settings.DATABASE_URL, limit=limit)
        return analyses
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
