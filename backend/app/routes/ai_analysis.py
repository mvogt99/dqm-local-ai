"""
AI Analysis Routes - Domain-Separated
Generated by RTX 5090 (Qwen2.5-Coder-32B-Instruct-AWQ)

Uses LOCAL AI (RTX 5090) for root cause analysis of data quality issues.
"""
from fastapi import APIRouter, HTTPException, Body
from pydantic import BaseModel
from typing import List, Dict, Any

from app.services.ai_analysis_service import analyze_data_quality, AIAnalysisResult

router = APIRouter(
    prefix="/ai-analysis",
    tags=["AI Analysis"]
)


class AnalysisRequest(BaseModel):
    """Request model for AI analysis."""
    violations: List[Dict[str, Any]]
    profile_data: Dict[str, Any]


class BatchAnalysisRequest(BaseModel):
    """Request model for batch AI analysis."""
    tables: List[Dict[str, Any]]


class FrontendAnalysisRequest(BaseModel):
    """Request model matching frontend format - Fixed by RTX 3050."""
    table_name: str
    profile_data: Dict[str, Any]
    issues: List[Any]  # Maps to 'violations' in backend


@router.post("/analyze")
async def analyze_from_frontend(request: FrontendAnalysisRequest = Body(...)):
    """
    Analyze data quality from frontend request format.

    Fixed by RTX 3050 to accept frontend format with table_name in body
    and issues mapped to violations.

    Uses LOCAL AI (RTX 5090) for root cause analysis.
    """
    try:
        # Map frontend 'issues' to backend 'violations'
        violations = []
        for issue in request.issues:
            if isinstance(issue, dict):
                violations.append(issue)
            else:
                violations.append({
                    "rule_type": "general",
                    "description": str(issue),
                    "violation_count": 1
                })

        result = await analyze_data_quality(
            violations=violations,
            profile_data=request.profile_data,
            table_name=request.table_name
        )

        return {
            "table_name": request.table_name,
            "analysis": result.raw_response,
            "root_causes": result.root_causes,
            "recommendations": result.recommendations,
            "confidence": result.confidence_score,
            "additional_rules": result.additional_rules
        }
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"AI analysis failed: {str(e)}"
        )


@router.post("/analyze/{table_name}")
async def analyze_table_violations(table_name: str, request: AnalysisRequest = Body(...)):
    """
    Analyze violations for a specific table using LOCAL AI.

    Uses RTX 5090 (Qwen2.5-Coder-32B) for intelligent root cause analysis.

    Args:
        table_name: Name of the table being analyzed
        request: Contains violations and profile data

    Returns:
        AI analysis with root causes, recommendations, and confidence score
    """
    try:
        result = await analyze_data_quality(
            violations=request.violations,
            profile_data=request.profile_data,
            table_name=table_name
        )
        return result.to_dict()
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"AI analysis failed: {str(e)}"
        )


@router.get("/analyses")
async def get_analyses():
    """
    Get stored analysis results.

    Note: Analysis persistence is not yet implemented.
    """
    return {
        "message": "Analyses are not persisted yet",
        "note": "Each analysis is computed on-demand using LOCAL AI"
    }


@router.get("/analyses/{analysis_id}")
async def get_analysis_by_id(analysis_id: str):
    """
    Get a specific analysis by ID.

    Note: Analysis persistence is not yet implemented.
    """
    raise HTTPException(
        status_code=404,
        detail="Analysis not found - persistence not yet implemented"
    )


@router.post("/batch-analyze")
async def batch_analyze_tables(request: BatchAnalysisRequest = Body(...)):
    """
    Analyze violations for multiple tables in batch.

    Processes each table sequentially using LOCAL AI for analysis.

    Args:
        request: Contains list of tables with their violations and profile data

    Returns:
        Combined AI analysis results for all tables
    """
    results = []

    for table in request.tables:
        table_name = table.get("table_name")
        if not table_name:
            raise HTTPException(
                status_code=400,
                detail="Each table must have a 'table_name' key"
            )

        violations = table.get("violations", [])
        profile_data = table.get("profile_data", {})

        try:
            result = await analyze_data_quality(
                violations=violations,
                profile_data=profile_data,
                table_name=table_name
            )
            results.append({
                "table_name": table_name,
                "analysis": result.to_dict()
            })
        except Exception as e:
            results.append({
                "table_name": table_name,
                "error": str(e),
                "analysis": None
            })

    return {
        "analyzed_count": len(results),
        "results": results
    }
