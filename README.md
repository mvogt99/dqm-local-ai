# DQM LOCAL AI

**Data Quality Management Application - Generated by LOCAL AI**

A comprehensive data quality management system that profiles database tables, manages data quality rules, and provides AI-powered root cause analysis for data quality issues.

## Overview

| Attribute | Value |
|-----------|-------|
| **Generated By** | LOCAL AI (RTX 5090 + RTX 3050) |
| **Model** | Qwen2.5-Coder-32B-Instruct-AWQ |
| **Port** | 8001 (Backend), 3001 (Frontend) |
| **Database** | PostgreSQL 15 (Northwind) |
| **Framework** | FastAPI + React + Vite |
| **Repository** | [github.com/mvogt99/dqm-local-ai](https://github.com/mvogt99/dqm-local-ai) |

## Architecture

```
+---------------------------------------------------------------------+
|                        DQM LOCAL AI                                 |
+---------------------------------------------------------------------+
|  Frontend (React + Vite) - Port 3001                                |
|  +-- Data Profiling Panel                                           |
|  +-- Data Quality Rules Panel                                       |
|  +-- Root Cause Analysis Panel                                      |
+---------------------------------------------------------------------+
|  Backend (FastAPI) - Port 8001                                      |
|  +-- /data-profiling    --> DataProfilingService                    |
|  +-- /data-quality      --> DataQualityRulesService                 |
|  +-- /ai-analysis       --> AIAnalysisService (RTX 5090)            |
+---------------------------------------------------------------------+
|  Database (PostgreSQL) - Port 5432                                  |
|  +-- Northwind Sample Database                                      |
+---------------------------------------------------------------------+
|  LOCAL AI (RTX 5090) - Port 8004                                    |
|  +-- Qwen2.5-Coder-32B-Instruct-AWQ                                 |
+---------------------------------------------------------------------+
```

## Features

### Data Profiling
- List available database tables (with whitelist security)
- Profile tables with comprehensive statistics:
  - Row count and column count
  - Null counts and percentages per column
  - Unique value counts
  - Min/max values for numeric columns
  - Sample values

### Data Quality Rules
- Create and manage data quality rules
- Rule types: NULL_CHECK, UNIQUE, RANGE, PATTERN
- Execute rules against live data
- Get suggestions based on profiling results
- Track execution results and failures

### AI Root Cause Analysis
- Powered by LOCAL AI (RTX 5090)
- Analyzes data quality violations
- Provides root causes and recommendations
- Suggests additional rules to create
- Confidence scoring for analysis results

## Quick Start

### Prerequisites
- Docker and Docker Compose
- LOCAL AI service running on port 8004 (for AI analysis)

### Using Docker Compose (Recommended)

```bash
# Clone the repository
git clone https://github.com/mvogt99/dqm-local-ai.git
cd dqm-local-ai

# Start all services
docker-compose up -d

# Services will be available at:
# Backend API: http://localhost:8001
# Frontend UI: http://localhost:3001
# PostgreSQL:  localhost:5432
```

### Manual Development Setup

```bash
# Backend
cd backend
pip install -r requirements.txt
uvicorn app.main:app --host 0.0.0.0 --port 8001 --reload

# Frontend
cd frontend
npm install
npm run dev
```

## Configuration

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `DATABASE_URL` | `postgresql://dqm_user:dqm_password@localhost:5432/northwind` | PostgreSQL connection string |
| `DATABASE_MIN_POOL_SIZE` | `2` | Minimum connection pool size |
| `DATABASE_MAX_POOL_SIZE` | `10` | Maximum connection pool size |
| `LOCAL_AI_RTX5090_URL` | `http://localhost:8004/v1` | RTX 5090 AI endpoint |
| `LOCAL_AI_RTX5090_MODEL` | `Qwen/Qwen2.5-Coder-32B-Instruct-AWQ` | Model for AI analysis |
| `LOCAL_AI_RTX3050_URL` | `http://localhost:8015/v1` | RTX 3050 AI endpoint |
| `LOCAL_AI_TIMEOUT` | `180` | AI request timeout (seconds) |
| `LOG_LEVEL` | `INFO` | Logging level |
| `CORS_ORIGINS` | `["http://localhost:3000", ...]` | Allowed CORS origins |

### Table Whitelist

For security, only whitelisted tables can be profiled:

```python
TABLE_WHITELIST = frozenset({
    "customers", "orders", "products", "employees", "order_details",
    "categories", "shippers", "suppliers", "territories", "region"
})
```

## API Reference

### Health Check
```http
GET /health
```
Response:
```json
{"status": "healthy", "app": "dqm-local-ai", "version": "1.0.0"}
```

### Data Profiling

#### List Tables
```http
GET /data-profiling/tables
```
Response:
```json
["customers", "orders", "products", "employees", ...]
```

#### Profile Table
```http
GET /data-profiling/profile/{table_name}
```
Response:
```json
{
  "table_name": "customers",
  "row_count": 91,
  "column_count": 11,
  "columns": [
    {
      "column_name": "customer_id",
      "data_type": "character",
      "is_nullable": false,
      "null_count": 0,
      "null_percent": 0.0,
      "unique_count": 91,
      "min_value": null,
      "max_value": null,
      "sample_values": ["ALFKI", "ANATR", "ANTON"]
    }
  ]
}
```

### Data Quality Rules

#### List Rules
```http
GET /data-quality/rules
```

#### Create Rule
```http
POST /data-quality/rules
Content-Type: application/json

{
  "name": "Customer ID Not Null",
  "table": "customers",
  "column": "customer_id",
  "rule_type": "NULL_CHECK",
  "definition": "SELECT * FROM customers WHERE customer_id IS NULL",
  "severity": "high"
}
```

#### Execute Rule
```http
POST /data-quality/rules/{rule_id}/execute
```

#### Suggest Rules
```http
POST /data-quality/suggest
Content-Type: application/json

[
  {"column_name": "customer_id", "null_percent": 0.0, "unique_count": 91}
]
```

### AI Analysis

#### Analyze Violations
```http
POST /ai-analysis/analyze/{table_name}
Content-Type: application/json

{
  "violations": [
    {"rule_type": "NULL_CHECK", "column": "contact_name", "violation_count": 5}
  ],
  "profile_data": {
    "row_count": 91,
    "column_count": 11
  }
}
```
Response:
```json
{
  "root_causes": [
    "Missing data during customer registration",
    "Legacy data migration issues"
  ],
  "recommendations": [
    "Add NOT NULL constraint after data cleanup",
    "Implement validation at ingestion point"
  ],
  "confidence_score": 0.85,
  "additional_rules": [
    {"rule_type": "NOT_NULL", "description": "contact_name - Required field"}
  ]
}
```

#### Batch Analyze
```http
POST /ai-analysis/batch-analyze
Content-Type: application/json

{
  "tables": [
    {
      "table_name": "customers",
      "violations": [...],
      "profile_data": {...}
    }
  ]
}
```

## Project Structure

```
dqm-local-ai/
+-- backend/
|   +-- app/
|   |   +-- main.py                 # FastAPI application entry point
|   |   +-- config.py               # Pydantic settings configuration
|   |   +-- api_routes.py           # Legacy API routes
|   |   +-- routes/
|   |   |   +-- data_profiling.py   # /data-profiling endpoints
|   |   |   +-- data_quality.py     # /data-quality endpoints
|   |   |   +-- ai_analysis.py      # /ai-analysis endpoints
|   |   +-- services/
|   |   |   +-- data_profiling_service.py   # Database profiling logic
|   |   |   +-- data_quality_rules.py       # Rule management
|   |   |   +-- ai_analysis_service.py      # LOCAL AI integration
|   |   +-- models/
|   |   |   +-- schemas.py          # Pydantic models
|   |   +-- middleware/
|   |   |   +-- auth.py             # Authentication (placeholder)
|   |   |   +-- cors_config.py      # CORS configuration
|   |   |   +-- rate_limiting.py    # Rate limiting
|   |   |   +-- request_logging.py  # Request logging
|   |   +-- tests/
|   |       +-- test_api_e2e.py     # End-to-end tests
|   +-- migrations/                 # Database initialization scripts
|   +-- Dockerfile
|   +-- requirements.txt
+-- frontend/
|   +-- src/
|   |   +-- App.js                  # Main React application
|   |   +-- components/
|   |   |   +-- DataProfiling.js
|   |   |   +-- DataQualityRules.js
|   |   |   +-- RootCauseAnalysis.js
|   |   +-- styles/
|   +-- Dockerfile
|   +-- nginx.conf
|   +-- package.json
+-- docker-compose.yml
+-- DIGITAL_TWIN_COMPLETE.md
+-- README.md
```

## Docker Services

| Service | Container | Port | Description |
|---------|-----------|------|-------------|
| `dqm-local-ai` | `dqm-local-ai` | 8001 | FastAPI backend |
| `postgres` | `dqm-postgres` | 5432 | PostgreSQL database |
| `frontend` | `dqm-local-ai-frontend` | 3001 | React frontend |

### Resource Limits

| Service | CPU | Memory |
|---------|-----|--------|
| Backend | 1.0 | 1GB |
| PostgreSQL | 0.5 | 512MB |
| Frontend | 0.25 | 128MB |

## Testing

### Run E2E Tests
```bash
cd backend
PYTHONPATH=. pytest tests/test_e2e.py -v
```

### Manual API Tests
```bash
# Health check
curl http://localhost:8001/health

# List tables
curl http://localhost:8001/data-profiling/tables

# Profile a table
curl http://localhost:8001/data-profiling/profile/customers

# List rules
curl http://localhost:8001/data-quality/rules
```

## Security Considerations

1. **Table Whitelist**: Only whitelisted tables can be accessed
2. **SQL Injection Prevention**:
   - Table names validated against whitelist before dynamic SQL
   - Column names from trusted source (information_schema)
   - PostgreSQL identifier quoting used for dynamic identifiers
3. **CORS**: Explicit origin configuration (no wildcards)
4. **Input Validation**: Pydantic models for all request bodies

## Digital Twin Methodology

This application was created using the Digital Twin methodology:

1. **Reference Implementation**: Expert AI created reference application
2. **Digital Twin Generation**: LOCAL AI generated equivalent implementation
3. **Gap Analysis**: E2E comparison tests identified differences
4. **Iterative Improvement**: Gaps fixed until 100% parity achieved
5. **Learning Storage**: Patterns stored in RAG (ChromaDB)

See `DIGITAL_TWIN_COMPLETE.md` for methodology details.

## Comparison with Expert AI

| Feature | LOCAL AI | Expert AI |
|---------|----------|-----------|
| E2E Tests | 7/7 passed | 4/7 passed |
| AI Analysis | RTX 5090 | RTX 5090 |
| Database | asyncpg | SQLAlchemy |
| Configuration | Pydantic Settings | Pydantic Settings |
| Routes | Domain-separated | Domain-separated |

## License

MIT License

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests
5. Submit a pull request

---

Generated by LOCAL AI (Qwen2.5-Coder-32B-Instruct-AWQ) using the Digital Twin methodology.
